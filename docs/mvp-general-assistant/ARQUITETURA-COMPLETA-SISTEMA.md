# Arquitetura Completa do Sistema npllm

**Data**: 2025-01-27  
**Vers√£o**: 1.0  
**Status**: üìä Arquitetura Completa Definida

---

## üìã Sum√°rio Executivo

Este documento apresenta a **arquitetura completa** do sistema npllm, incluindo:

1. **Todas as LLMs utilizadas** e suas fun√ß√µes
2. **Sistema de mem√≥ria** (curto, m√©dio, longo prazo)
3. **Sistema de aprendizado** (MAS, Replay, Backpropamine)
4. **Sistema de feedback** (emocional + impl√≠cito)
5. **Sistema de consolida√ß√£o** (sono)
6. **Processos psicol√≥gicos** integrados
7. **Fluxo completo** de intera√ß√£o

---

## üß† LLMs Utilizadas no Sistema

### 1. LLM Base (CodeLlama 3B) - C√≥rtex Pr√©-Frontal (PFC)

**Fun√ß√£o**: Racioc√≠nio principal, planejamento, controle executivo

**Caracter√≠sticas**:
- ‚úÖ **Modelo**: CodeLlama 3B quantizado 4-bit
- ‚úÖ **Tamanho**: ~3 bilh√µes de par√¢metros
- ‚úÖ **Status**: Est√°tico (n√£o muda durante uso)
- ‚úÖ **Atualiza√ß√£o**: Apenas durante "sono" (consolida√ß√£o)
- ‚úÖ **Uso**: Processamento principal de c√≥digo e arquitetura

**Onde √© Usado**:
- Gera√ß√£o de c√≥digo arquitetural
- An√°lise de padr√µes
- Sugest√µes arquiteturais
- Racioc√≠nio e planejamento

**Integra√ß√£o**:
- Recebe contexto do RAG (Hipocampo)
- Usa LoRA Adapters para adapta√ß√£o r√°pida
- Modulado pelo Modulador (sele√ß√£o de adapters)

---

### 2. Modulador (1-5M par√¢metros) - C√≥rtex Pr√©-Frontal (PFC)

**Fun√ß√£o**: Sele√ß√£o e modula√ß√£o de adapters baseado em contexto

**Caracter√≠sticas**:
- ‚úÖ **Modelo**: Pequeno (1-5M par√¢metros)
- ‚úÖ **Tamanho**: Muito menor que LLM Base
- ‚úÖ **Status**: Pode usar Backpropamine (experimental)
- ‚úÖ **Atualiza√ß√£o**: Durante uso (se Backpropamine) ou durante sono
- ‚úÖ **Uso**: Decis√£o de qual adapter usar

**Onde √© Usado**:
- An√°lise de hidden states do LLM Base
- Gera√ß√£o de sinais de modula√ß√£o
- Sele√ß√£o de adapters apropriados
- Controle de intensidade de adapta√ß√£o

**Integra√ß√£o**:
- Recebe hidden states do LLM Base (bottom-up)
- Gera sinais de modula√ß√£o (top-down)
- Controla LoRA Adapters
- Treinado com RL (PPO)

---

### 3. Cerebelo (100M-500M par√¢metros) - Experimental

**Fun√ß√£o**: Padr√µes espec√≠ficos, automatiza√ß√£o, aprendizado r√°pido

**Caracter√≠sticas**:
- ‚ö†Ô∏è **Modelo**: M√©dio (100M-500M par√¢metros)
- ‚ö†Ô∏è **Status**: Experimental (Fase 2)
- ‚ö†Ô∏è **Atualiza√ß√£o**: Backpropamine (mudan√ßas reais de pesos)
- ‚ö†Ô∏è **Uso**: Padr√µes espec√≠ficos, automatiza√ß√£o

**Onde √© Usado**:
- Padr√µes arquiteturais espec√≠ficos
- Automatiza√ß√£o de tarefas repetitivas
- Aprendizado r√°pido de novos padr√µes
- Integra√ß√£o com sistema motor

**Integra√ß√£o**:
- Recebe padr√µes do sistema sensorial
- Aprende rapidamente com Backpropamine
- Integra com sistema motor (tool calling)
- Consolida durante sono

---

### 4. LoRA Adapters (pesos adicionais) - Adapta√ß√£o R√°pida

**Fun√ß√£o**: Adapta√ß√£o r√°pida a contextos espec√≠ficos

**Caracter√≠sticas**:
- ‚úÖ **Modelo**: Pesos adicionais (n√£o modelo completo)
- ‚úÖ **Tamanho**: Muito menor que modelo base
- ‚úÖ **Status**: M√∫ltiplos adapters por contexto
- ‚úÖ **Atualiza√ß√£o**: Durante uso (treinamento incremental)
- ‚úÖ **Uso**: Especializa√ß√£o por contexto (ex: Odoo, Django, React)

**Onde √© Usado**:
- Adapta√ß√£o a contextos espec√≠ficos
- Especializa√ß√£o por projeto
- Aprendizado r√°pido sem mudar modelo base

**Integra√ß√£o**:
- Aplicados ao LLM Base
- Selecionados pelo Modulador
- Treinados com feedback emocional
- Consolidados durante sono

---

## üèóÔ∏è Arquitetura Completa do Sistema

```mermaid
graph TB
    subgraph "Entrada"
        USER[Usu√°rio]
        LINUX[Linux Sistema]
    end
    
    subgraph "Sistema Sensorial"
        SENS[Sistema Sensorial<br/>Filesystem, Processos, Network]
        PERC[Percep√ß√£o<br/>Pattern Recognition<br/>Structure Parser]
    end
    
    subgraph "Mem√≥ria"
        CACHE[Cache R√°pido<br/>Mem√≥ria Curta]
        WORKING[Mem√≥ria Trabalho<br/>Contexto Atual]
        POSTGRES[PostgreSQL + pgvector<br/>Mem√≥ria M√©dia<br/>Hipocampo]
    end
    
    subgraph "LLMs e Processamento"
        LLM_BASE[LLM Base<br/>CodeLlama 3B<br/>PFC - Racioc√≠nio]
        MODULATOR[Modulador<br/>1-5M par√¢metros<br/>Sele√ß√£o Adapters]
        LORA[LoRA Adapters<br/>Adapta√ß√£o R√°pida]
        CEREBELO[Cerebelo*<br/>100M-500M<br/>Padr√µes Espec√≠ficos]
    end
    
    subgraph "Aprendizado"
        MAS[MAS<br/>Preserva√ß√£o]
        REPLAY[Replay Buffer<br/>Mem√≥rias Importantes]
        BACKPROP[Backpropamine*<br/>Plasticidade Real]
        RL[RL PPO<br/>Sistema Dopamin√©rgico]
    end
    
    subgraph "Feedback"
        IMPLICIT[Feedback Impl√≠cito<br/>Aceitar/Editar/Deletar]
        EMOTIONAL[Feedback Emocional<br/>Frustra√ß√£o/Satisfa√ß√£o/Confian√ßa]
        INTEGRATE[Integra√ß√£o Feedback<br/>70% Impl√≠cito + 30% Emocional]
    end
    
    subgraph "Consolida√ß√£o"
        SLEEP[Consolida√ß√£o Durante Sono<br/>Hipocampo ‚Üí C√≥rtex]
        FT[Fine-tuning<br/>Incremental]
    end
    
    subgraph "Processos Psicol√≥gicos"
        THINK[Pensamento]
        EMOT_PROC[Emo√ß√£o]
        MOTIV[Motiva√ß√£o]
        META[Metacogni√ß√£o]
        PROB[Resolu√ß√£o de Problemas]
        DEC[Tomada de Decis√£o]
        PLAN[Planejamento]
    end
    
    subgraph "Sa√≠da"
        MOTOR[Sistema Motor<br/>Tool Calling]
        AUTO[Sistema Aut√¥nomo<br/>Services]
    end
    
    USER --> SENS
    LINUX --> SENS
    SENS --> PERC
    PERC --> CACHE
    CACHE --> WORKING
    WORKING --> POSTGRES
    
    POSTGRES --> LLM_BASE
    LLM_BASE --> MODULATOR
    MODULATOR --> LORA
    LORA --> LLM_BASE
    
    CEREBELO -.-> MOTOR
    
    USER --> IMPLICIT
    USER --> EMOTIONAL
    IMPLICIT --> INTEGRATE
    EMOTIONAL --> INTEGRATE
    INTEGRATE --> REPLAY
    INTEGRATE --> RL
    
    REPLAY --> POSTGRES
    RL --> MODULATOR
    RL --> BACKPROP
    BACKPROP --> MAS
    MAS --> LLM_BASE
    
    POSTGRES --> SLEEP
    SLEEP --> FT
    FT --> LLM_BASE
    FT --> LORA
    
    LLM_BASE --> THINK
    THINK --> EMOT_PROC
    EMOT_PROC --> MOTIV
    MOTIV --> PLAN
    THINK --> PROB
    THINK --> DEC
    META --> THINK
    
    THINK --> MOTOR
    MOTOR --> AUTO
    
    style LLM_BASE fill:#e1f5ff
    style MODULATOR fill:#fff4e1
    style LORA fill:#ffe1f5
    style CEREBELO fill:#f0e1ff
    style POSTGRES fill:#ccffcc
    style MAS fill:#ffcccc
    style REPLAY fill:#ffffcc
    style BACKPROP fill:#ffcccc
    style RL fill:#e1ffe1
    style INTEGRATE fill:#ffccff
```

**Legenda**:
- `*` = Componente experimental (Backpropamine, Cerebelo)
- Cores diferentes = Diferentes subsistemas

---

## üîÑ Fluxo Completo: Intera√ß√£o ‚Üí Processamento ‚Üí Consolida√ß√£o

```mermaid
sequenceDiagram
    participant USER as Usu√°rio
    participant SENS as Sistema Sensorial
    participant CACHE as Cache R√°pido
    participant POSTGRES as PostgreSQL<br/>(Hipocampo)
    participant LLM as LLM Base<br/>(PFC)
    participant MOD as Modulador
    participant LORA as LoRA Adapters
    participant REPLAY as Replay Buffer
    participant FEEDBACK as Feedback Emocional
    participant RL as RL PPO
    participant SLEEP as Consolida√ß√£o<br/>(Sono)
    
    USER->>SENS: Query/C√≥digo
    SENS->>CACHE: Consulta cache
    CACHE->>POSTGRES: Busca sem√¢ntica (se n√£o encontrar)
    POSTGRES-->>CACHE: Resultados relevantes
    CACHE->>LLM: Contexto + Query
    
    LLM->>MOD: Hidden states
    MOD->>MOD: Analisa contexto
    MOD->>LORA: Seleciona adapters
    LORA->>LLM: Adapta√ß√£o aplicada
    LLM->>USER: Resposta/Sugest√£o
    
    USER->>FEEDBACK: Emo√ß√£o (frustra√ß√£o/satisfa√ß√£o)
    USER->>FEEDBACK: A√ß√£o (aceitar/editar/deletar)
    FEEDBACK->>REPLAY: Feedback integrado (70% + 30%)
    REPLAY->>REPLAY: Avalia import√¢ncia
    REPLAY->>POSTGRES: Persiste conhecimento importante
    
    FEEDBACK->>RL: Recompensa (feedback emocional + impl√≠cito)
    RL->>MOD: Atualiza pol√≠tica (PPO)
    RL->>LORA: Ajusta adapters
    
    Note over POSTGRES,SLEEP: Durante "Sono" (Consolida√ß√£o)
    POSTGRES->>REPLAY: Conhecimento acumulado
    REPLAY->>REPLAY: Filtra por feedback emocional
    REPLAY->>SLEEP: Conhecimento importante
    SLEEP->>LLM: Atualiza pesos (fine-tuning)
    SLEEP->>LORA: Consolida adapters
```

---

## üìä Detalhamento: Componentes e Suas Fun√ß√µes

### 1. Sistema de Mem√≥ria (3 N√≠veis)

#### Mem√≥ria de Curto Prazo (Cache R√°pido)
- **Componente**: Redis/Mem√≥ria
- **Fun√ß√£o**: Consultas r√°pidas, contexto imediato
- **Velocidade**: ‚ö° Muito r√°pida
- **Persist√™ncia**: ‚ö†Ô∏è Vol√°til
- **Consulta**: PostgreSQL quando necess√°rio

#### Mem√≥ria de M√©dio Prazo (Hipocampo)
- **Componente**: PostgreSQL + pgvector
- **Fun√ß√£o**: Consolida conhecimento, busca sem√¢ntica
- **Velocidade**: üê¢ R√°pida
- **Persist√™ncia**: ‚úÖ Persistente
- **Consolida√ß√£o**: Durante sono ‚Üí Longo prazo

#### Mem√≥ria de Longo Prazo (C√≥rtex)
- **Componente**: Pesos da LLM Base + LoRA Adapters
- **Fun√ß√£o**: Conhecimento consolidado
- **Velocidade**: üêå Lenta (consulta)
- **Persist√™ncia**: ‚úÖ Persistente
- **Atualiza√ß√£o**: Durante sono (consolida√ß√£o)

---

### 2. Sistema de Aprendizado

#### MAS (Memory Aware Synapses)
- **Fun√ß√£o**: Preserva conhecimento importante
- **Mecanismo**: Calcula import√¢ncia de par√¢metros
- **Uso**: Durante consolida√ß√£o (sono)
- **Status**: ‚úÖ Implementado

#### Replay Buffer
- **Fun√ß√£o**: Reapresenta mem√≥rias importantes
- **Mecanismo**: Armazena experi√™ncias com feedback positivo
- **Uso**: Durante treinamento
- **Status**: ‚úÖ Implementado

#### Backpropamine (Experimental)
- **Fun√ß√£o**: Mudan√ßas reais de pesos
- **Mecanismo**: Plasticidade sin√°ptica diferenci√°vel
- **Uso**: Modulador, Cerebelo, Aten√ß√£o
- **Status**: ‚ö†Ô∏è Experimental (Fase 2)

#### RL PPO (Sistema Dopamin√©rgico)
- **Fun√ß√£o**: Aprendizado por refor√ßo
- **Mecanismo**: TD Learning com feedback integrado
- **Uso**: Treinamento do Modulador
- **Status**: ‚úÖ Implementado

---

### 3. Sistema de Feedback

#### Feedback Impl√≠cito (70%)
- **Fonte**: A√ß√µes do usu√°rio
- **Sinais**: Aceitar (+1.0), Editar (+0.3 a +0.8), Deletar (-0.5)
- **Uso**: Recompensa prim√°ria no RL

#### Feedback Emocional (30%)
- **Fonte**: Emo√ß√µes do usu√°rio
- **Sinais**: Satisfa√ß√£o (+0.8 a +1.0), Confian√ßa (+0.9 a +1.0), Frustra√ß√£o (-1.0 a 0.0)
- **Uso**: Recompensa secund√°ria no RL, prioriza√ß√£o no Replay

#### Integra√ß√£o
- **F√≥rmula**: `r_total = 0.7 * r_impl√≠cito + 0.3 * r_emocional`
- **Uso**: Replay Buffer, RL, Consolida√ß√£o

---

### 4. Sistema de Consolida√ß√£o (Sono)

#### Processo
1. **Coleta**: Extrai conhecimento do PostgreSQL
2. **Filtragem**: Filtra por feedback emocional (prioriza satisfa√ß√£o)
3. **Preserva√ß√£o**: MAS preserva conhecimento antigo importante
4. **Treinamento**: Fine-tuning incremental
5. **Armazenamento**: Atualiza pesos da LLM Base e LoRA Adapters

#### Quando Acontece
- Durante per√≠odo de inatividade
- Ap√≥s acumular conhecimento suficiente
- Agendado periodicamente

---

## üéØ Resumo: Quantas LLMs e Onde

| LLM | Tamanho | Fun√ß√£o | Onde Usado | Atualiza√ß√£o |
|-----|---------|--------|------------|-------------|
| **LLM Base** | 3B | Racioc√≠nio principal | PFC, processamento principal | Durante sono |
| **Modulador** | 1-5M | Sele√ß√£o de adapters | PFC, controle de adapters | Durante uso (se Backpropamine) ou sono |
| **Cerebelo** | 100M-500M | Padr√µes espec√≠ficos | Automatiza√ß√£o, padr√µes | Backpropamine (experimental) |
| **LoRA Adapters** | Pesos adicionais | Adapta√ß√£o r√°pida | Especializa√ß√£o por contexto | Durante uso e sono |

**Total**: 2-3 modelos principais + m√∫ltiplos adapters

---

## üîÑ Fluxo Detalhado: Como Tudo Funciona Juntos

### Fase 1: Intera√ß√£o

1. **Usu√°rio faz query/c√≥digo**
2. **Sistema Sensorial** coleta dados
3. **Cache R√°pido** verifica se tem resposta
4. Se n√£o, **PostgreSQL** busca sem√¢ntica
5. **LLM Base** recebe contexto + query
6. **Modulador** analisa e seleciona adapters
7. **LoRA Adapters** adaptam resposta
8. **LLM Base** gera resposta final

### Fase 2: Feedback

1. **Usu√°rio** fornece feedback (emocional + impl√≠cito)
2. **Sistema de Feedback** integra (70% + 30%)
3. **Replay Buffer** avalia import√¢ncia
4. **RL PPO** atualiza pol√≠tica do Modulador
5. **Conhecimento importante** √© persistido no PostgreSQL

### Fase 3: Consolida√ß√£o (Sono)

1. **PostgreSQL** acumula conhecimento
2. **Replay Buffer** filtra por feedback emocional
3. **MAS** preserva conhecimento antigo importante
4. **Fine-tuning** consolida conhecimento
5. **Pesos da LLM** s√£o atualizados
6. **LoRA Adapters** s√£o consolidados

---

## üìä Tabela Comparativa: Componentes do Sistema

| Componente | Tipo | Fun√ß√£o | Status | Prioridade |
|------------|------|--------|--------|------------|
| **LLM Base** | Modelo | Racioc√≠nio principal | ‚úÖ Implementado | üî¥ Cr√≠tica |
| **Modulador** | Modelo Pequeno | Sele√ß√£o adapters | ‚úÖ Implementado | üî¥ Cr√≠tica |
| **LoRA Adapters** | Pesos | Adapta√ß√£o r√°pida | ‚úÖ Implementado | üî¥ Cr√≠tica |
| **Cerebelo** | Modelo M√©dio | Padr√µes espec√≠ficos | ‚ö†Ô∏è Experimental | üü° Alta |
| **RAG** | Mem√≥ria | Busca sem√¢ntica | ‚úÖ Implementado | üî¥ Cr√≠tica |
| **MAS** | Aprendizado | Preserva√ß√£o | ‚úÖ Implementado | üü° Alta |
| **Replay** | Aprendizado | Mem√≥rias importantes | ‚úÖ Implementado | üü° Alta |
| **Backpropamine** | Aprendizado | Plasticidade real | ‚ö†Ô∏è Experimental | üîµ Baixa |
| **RL PPO** | Aprendizado | Sistema dopamin√©rgico | ‚úÖ Implementado | üü° Alta |
| **Feedback Emocional** | Feedback | Prioriza√ß√£o | ‚ö†Ô∏è B√°sico | üî¥ Cr√≠tica |
| **Consolida√ß√£o Sono** | Consolida√ß√£o | Transfer√™ncia conhecimento | ‚ö†Ô∏è Planejado | üü° Alta |

---

## üéØ Conclus√£o

### Arquitetura Completa

O sistema npllm utiliza:

1. **2-3 modelos principais**:
   - LLM Base (3B) - Racioc√≠nio principal
   - Modulador (1-5M) - Sele√ß√£o de adapters
   - Cerebelo (100M-500M) - Padr√µes espec√≠ficos (experimental)

2. **M√∫ltiplos LoRA Adapters**:
   - Adapta√ß√£o r√°pida por contexto
   - Especializa√ß√£o por projeto

3. **Sistema de mem√≥ria hier√°rquica**:
   - Curto prazo (cache)
   - M√©dio prazo (PostgreSQL)
   - Longo prazo (pesos da LLM)

4. **Sistema de aprendizado integrado**:
   - MAS (preserva√ß√£o)
   - Replay (mem√≥rias importantes)
   - Backpropamine (plasticidade real - experimental)
   - RL PPO (sistema dopamin√©rgico)

5. **Sistema de feedback emocional**:
   - Feedback impl√≠cito (70%)
   - Feedback emocional (30%)
   - Integra√ß√£o para prioriza√ß√£o

6. **Sistema de consolida√ß√£o**:
   - Durante sono
   - Filtragem por feedback emocional
   - Transfer√™ncia para pesos da LLM

---

**Data de Cria√ß√£o**: 2025-01-27  
**√öltima Atualiza√ß√£o**: 2025-01-27  
**Status**: ‚úÖ Completo - Arquitetura Completa Definida

