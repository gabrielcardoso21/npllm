# Arquitetura Final Completa npllm - 2025
## Abordagem H√≠brida: Pragm√°tica + Experimental

**Data**: 2025-01-27  
**Vers√£o**: 2.0 (Revisada ap√≥s pesquisa profunda)  
**Status**: üü° Proposta Final

---

## üìã Sum√°rio Executivo

Este documento apresenta a **arquitetura final completa** do npllm, combinando:

1. **Abordagem Pragm√°tica**: Tecnologias comprovadas (LoRA, RAG, MAS) para sistema funcional imediato
2. **Abordagem Experimental**: Backpropamine e consolida√ß√£o durante "sono" em componentes espec√≠ficos onde fazem sentido
3. **Integra√ß√£o Completa**: Todos os processos psicol√≥gicos e componentes biol√≥gicos

**Princ√≠pio**: Usar o melhor de ambos os mundos - pragm√°tico onde necess√°rio, experimental onde adiciona valor real.

---

## üß† Arquitetura Completa do Sistema

### Vis√£o Geral do Sistema

```mermaid
graph TB
    subgraph "Sistema Nervoso Central (SNC) - C√©rebro"
        PFC[PFC: LLM Base<br/>CodeLlama 3B<br/>Est√°tico]
        HIP[Hipocampo: RAG<br/>PostgreSQL + pgvector<br/>Mem√≥ria Epis√≥dica]
        PLA[Plasticidade Sin√°ptica<br/>LoRA + MAS + Backpropamine*]
        RL[Sistema Dopamin√©rgico<br/>PPO + TD Learning]
        CEREB[Cerebelo*<br/>Modelo Pequeno<br/>100M-500M]
    end
    
    subgraph "Sistema Nervoso Perif√©rico (SNP) - Linux"
        SENS[Sistema Sensorial<br/>Filesystem, Processos,<br/>Network, I/O]
        MOTOR[Sistema Motor<br/>Tool Calling,<br/>File Operations]
        AUTO[Sistema Aut√¥nomo<br/>Services, Daemons]
    end
    
    subgraph "Processos Psicol√≥gicos"
        PERC[Percep√ß√£o]
        ATT[Aten√ß√£o]
        MEM[Mem√≥ria]
        THINK[Pensamento]
        LANG[Linguagem]
        EMOT[Emo√ß√£o]
        MOTIV[Motiva√ß√£o]
        META[Metacogni√ß√£o]
        CONSC[Consci√™ncia]
        CREAT[Criatividade]
        PROB[Resolu√ß√£o de Problemas]
        DEC[Tomada de Decis√£o]
        PLAN[Planejamento]
        EXEC[Controle Executivo]
    end
    
    SENS --> PERC
    PERC --> ATT
    ATT --> MEM
    MEM --> HIP
    HIP --> PFC
    PFC --> THINK
    THINK --> LANG
    THINK --> PROB
    THINK --> CREAT
    THINK --> DEC
    THINK --> PLAN
    
    RL --> PLA
    PLA --> PFC
    RL --> EMOT
    EMOT --> MOTIV
    MOTIV --> PLAN
    
    META --> THINK
    CONSC --> META
    EXEC --> PLAN
    EXEC --> DEC
    
    PFC --> MOTOR
    MOTOR --> AUTO
    
    CEREB -.-> MOTOR
    
    style PFC fill:#e1f5ff
    style HIP fill:#fff4e1
    style PLA fill:#ffe1f5
    style RL fill:#e1ffe1
    style CEREB fill:#f0e1ff
```

**Legenda**:
- `*` = Componente experimental (Backpropamine, Cerebelo)
- Cores diferentes = Diferentes subsistemas

---

## üèóÔ∏è Arquitetura Detalhada por Camada

### Camada 1: Infraestrutura Base (Pragm√°tica)

```mermaid
graph LR
    subgraph "Camada 1: Base"
        LLM[LLM Base<br/>CodeLlama 3B<br/>Quantizado 4-bit]
        RAG[RAG<br/>PostgreSQL + pgvector<br/>HNSW Index]
        MAS[MAS<br/>Memory Aware Synapses<br/>Preserva√ß√£o]
    end
    
    LLM --> RAG
    RAG --> MAS
    MAS --> LLM
    
    style LLM fill:#e1f5ff
    style RAG fill:#fff4e1
    style MAS fill:#ffe1f5
```

**Componentes**:
- ‚úÖ **LLM Base**: CodeLlama 3B quantizado (j√° implementado)
- ‚úÖ **RAG**: PostgreSQL + pgvector (j√° implementado)
- ‚úÖ **MAS**: Memory Aware Synapses (j√° implementado)

**Status**: ‚úÖ **Tudo implementado e funcional**

---

### Camada 2: Adapta√ß√£o e Aprendizado (H√≠brida)

```mermaid
graph TB
    subgraph "Camada 2: Adapta√ß√£o"
        LORA[LoRA Adapters<br/>Adapta√ß√£o R√°pida<br/>Por Contexto]
        MAS2[MAS<br/>Preserva√ß√£o<br/>Conhecimento Importante]
        BACKPROP[Backpropamine*<br/>Plasticidade Real<br/>Cerebelo + Aten√ß√£o]
    end
    
    subgraph "Controle"
        RL2[RL PPO<br/>Sele√ß√£o de Adapters<br/>Feedback Integrado]
    end
    
    RL2 --> LORA
    RL2 --> BACKPROP
    LORA --> MAS2
    BACKPROP --> MAS2
    
    style LORA fill:#e1f5ff
    style MAS2 fill:#ffe1f5
    style BACKPROP fill:#ffcccc
    style RL2 fill:#e1ffe1
```

**Componentes**:
- ‚úÖ **LoRA Adapters**: Adapta√ß√£o r√°pida por contexto (a implementar)
- ‚úÖ **MAS**: Preserva√ß√£o de conhecimento (j√° implementado)
- ‚ö†Ô∏è **Backpropamine**: Plasticidade real (experimental, em componentes espec√≠ficos)

**Onde usar Backpropamine**:
1. **Cerebelo** (modelo pequeno 100M-500M) - padr√µes espec√≠ficos
2. **Aten√ß√£o Neuromodulada** - controle contextual de aten√ß√£o
3. **Sistema de Consolida√ß√£o** - transfer√™ncia hipocampo ‚Üí c√≥rtex

**Status**: ‚ö†Ô∏è **Parcialmente implementado** (MAS ‚úÖ, LoRA ‚è≥, Backpropamine ‚è≥)

---

### Camada 3: Mem√≥ria e Consolida√ß√£o (H√≠brida)

```mermaid
graph LR
    subgraph "Mem√≥ria"
        SENS_MEM[Mem√≥ria Sensorial<br/>Cache Imediato]
        WORK_MEM[Mem√≥ria de Trabalho<br/>Contexto Atual]
        SHORT_MEM[Mem√≥ria Curto Prazo<br/>Hipocampo - RAG]
        LONG_MEM[Mem√≥ria Longo Prazo<br/>C√≥rtex - LLM Base]
    end
    
    subgraph "Consolida√ß√£o"
        REPLAY[Replay<br/>Mem√≥rias Importantes]
        FT[Fine-tuning<br/>Incremental]
        SLEEP[Consolida√ß√£o<br/>Durante Sono*]
    end
    
    SENS_MEM --> WORK_MEM
    WORK_MEM --> SHORT_MEM
    SHORT_MEM --> LONG_MEM
    
    SHORT_MEM --> REPLAY
    REPLAY --> FT
    FT --> LONG_MEM
    
    SHORT_MEM -.-> SLEEP
    SLEEP -.-> LONG_MEM
    
    style SENS_MEM fill:#e1f5ff
    style WORK_MEM fill:#fff4e1
    style SHORT_MEM fill:#ffe1f5
    style LONG_MEM fill:#e1ffe1
    style SLEEP fill:#ffcccc
```

**Componentes**:
- ‚úÖ **Hierarquia de Mem√≥ria**: Sensorial ‚Üí Trabalho ‚Üí Curto ‚Üí Longo (a implementar estrutura)
- ‚úÖ **Replay + Fine-tuning**: Consolida√ß√£o incremental (a implementar)
- ‚ö†Ô∏è **Consolida√ß√£o Durante Sono**: Processo offline experimental (a implementar)

**Onde usar Consolida√ß√£o Durante Sono**:
1. **Transfer√™ncia Hipocampo ‚Üí C√≥rtex**: Consolidar mem√≥rias epis√≥dicas importantes
2. **Replay de Mem√≥rias**: Reativar e consolidar experi√™ncias significativas
3. **Limpeza Seletiva**: Remover mem√≥rias antigas n√£o consolidadas

**Status**: ‚ö†Ô∏è **Parcialmente implementado** (RAG ‚úÖ, Consolida√ß√£o ‚è≥)

---

### Camada 4: Sistema Dopamin√©rgico (Pragm√°tica)

```mermaid
graph TB
    subgraph "Sistema Dopamin√©rgico"
        PPO[PPO<br/>Proximal Policy<br/>Optimization]
        TD[TD Learning<br/>Temporal Difference<br/>Prediction Error]
        FEEDBACK[Feedback Integrado<br/>70% Impl√≠cito<br/>30% Emocional]
    end
    
    subgraph "A√ß√µes"
        ACTION1[Selecionar Adapter]
        ACTION2[Controlar Plasticidade]
        ACTION3[Modular Aten√ß√£o]
    end
    
    FEEDBACK --> TD
    TD --> PPO
    PPO --> ACTION1
    PPO --> ACTION2
    PPO --> ACTION3
    
    style PPO fill:#e1ffe1
    style TD fill:#fff4e1
    style FEEDBACK fill:#ffe1f5
```

**Componentes**:
- ‚úÖ **PPO**: J√° implementado (Stable-Baselines3)
- ‚úÖ **Feedback Integrado**: Estrutura implementada
- ‚ö†Ô∏è **TD Learning**: A implementar (melhorar PPO atual)

**Status**: ‚úÖ **Estrutura implementada**, precisa melhorar integra√ß√£o

---

### Camada 5: Processos Psicol√≥gicos (H√≠brida)

```mermaid
graph TB
    subgraph "Processos Fundamentais"
        PERC2[Percep√ß√£o<br/>Pattern Recognition<br/>Structure Parser]
        ATT2[Aten√ß√£o<br/>Selective + Sustained<br/>Neuromodula√ß√£o*]
        MEM2[Mem√≥ria<br/>Hierarquia Completa]
    end
    
    subgraph "Processos Cognitivos"
        THINK2[Pensamento<br/>Reasoning + Problem Solving]
        LANG2[Linguagem<br/>Comprehension + Production]
        LEARN[Aprendizado<br/>Associativo + RL + Observacional]
    end
    
    subgraph "Processos Afetivos"
        EMOT2[Emo√ß√£o<br/>Valence + Arousal]
        MOTIV2[Motiva√ß√£o<br/>Goals + Values]
    end
    
    subgraph "Processos Metacognitivos"
        CONSC2[Consci√™ncia<br/>Self-Awareness]
        META2[Metacogni√ß√£o<br/>Monitoring + Regulation]
    end
    
    subgraph "Processos de A√ß√£o"
        PROB2[Resolu√ß√£o de Problemas]
        CREAT2[Criatividade]
        DEC2[Tomada de Decis√£o]
        PLAN2[Planejamento]
        EXEC2[Controle Executivo]
    end
    
    PERC2 --> ATT2
    ATT2 --> MEM2
    MEM2 --> THINK2
    THINK2 --> LANG2
    THINK2 --> LEARN
    
    EMOT2 --> MOTIV2
    MOTIV2 --> PLAN2
    
    CONSC2 --> META2
    META2 --> THINK2
    
    THINK2 --> PROB2
    THINK2 --> CREAT2
    THINK2 --> DEC2
    PLAN2 --> EXEC2
    
    style ATT2 fill:#ffcccc
    style LEARN fill:#ffcccc
```

**Onde usar Backpropamine nos Processos Psicol√≥gicos**:
1. **Aten√ß√£o Neuromodulada**: Backpropamine controla onde focar
2. **Aprendizado**: Backpropamine para adapta√ß√£o r√°pida
3. **Consolida√ß√£o**: Backpropamine para transfer√™ncia de mem√≥ria

**Status**: ‚è≥ **A implementar** (estrutura planejada)

---

## üîÑ Fluxo Completo de Processamento

### Fluxo Online (Durante Uso)

```mermaid
sequenceDiagram
    participant User as Usu√°rio
    participant SENS as Sistema Sensorial
    participant PERC as Percep√ß√£o
    participant ATT as Aten√ß√£o
    participant MEM as Mem√≥ria
    participant RAG as RAG (Hipocampo)
    participant PFC as PFC (LLM Base)
    participant LORA as LoRA Adapters
    participant RL as Sistema RL
    participant MOTOR as Sistema Motor
    participant BACKPROP as Backpropamine*
    
    User->>SENS: Entrada (c√≥digo/texto)
    SENS->>PERC: Dados brutos
    PERC->>ATT: Informa√ß√£o processada
    ATT->>MEM: Informa√ß√£o filtrada
    MEM->>RAG: Busca mem√≥rias relevantes
    RAG-->>MEM: Mem√≥rias recuperadas
    MEM->>PFC: Contexto completo
    PFC->>LORA: Processa com adapter
    LORA->>RL: Solicita sele√ß√£o
    RL->>LORA: Adapter selecionado
    LORA->>BACKPROP: Ajusta plasticidade (Cerebelo)
    BACKPROP-->>LORA: Pesos ajustados
    LORA->>PFC: Resposta processada
    PFC->>MOTOR: A√ß√£o gerada
    MOTOR->>User: Resposta
    RL->>BACKPROP: Feedback (recompensa)
    BACKPROP->>LORA: Ajuste de plasticidade
    RAG->>RAG: Armazena experi√™ncia
```

**Legenda**:
- `*` = Componente experimental (Backpropamine)

---

### Fluxo Offline (Durante "Sono" - Consolida√ß√£o)

```mermaid
sequenceDiagram
    participant RAG as RAG (Hipocampo)
    participant SELECT as Sele√ß√£o de Mem√≥rias
    participant REPLAY as Replay
    participant MAS as MAS
    participant FT as Fine-tuning
    participant BACKPROP as Backpropamine*
    participant PFC as PFC (LLM Base)
    participant CLEAN as Limpeza
    
    Note over RAG: Mem√≥rias Epis√≥dicas<br/>Acumuladas
    
    RAG->>SELECT: Seleciona mem√≥rias importantes
    SELECT->>REPLAY: Mem√≥rias para replay
    REPLAY->>MAS: Calcula import√¢ncia
    MAS->>FT: Fine-tuning com preserva√ß√£o
    FT->>BACKPROP: Consolida√ß√£o com plasticidade
    BACKPROP->>PFC: Transfere para modelo base
    PFC->>PFC: Conhecimento consolidado
    SELECT->>CLEAN: Mem√≥rias antigas
    CLEAN->>RAG: Remove n√£o consolidadas
    
    Note over PFC: Conhecimento<br/>Consolidado
```

**Legenda**:
- `*` = Componente experimental (Backpropamine na consolida√ß√£o)

---

## üìä Matriz de Tecnologias por Componente

| Componente | Tecnologia Pragm√°tica | Tecnologia Experimental | Status |
|------------|----------------------|------------------------|--------|
| **LLM Base** | CodeLlama 3B Quantizado | - | ‚úÖ Implementado |
| **Mem√≥ria Epis√≥dica** | PostgreSQL + pgvector | - | ‚úÖ Implementado |
| **Preserva√ß√£o** | MAS | - | ‚úÖ Implementado |
| **Adapta√ß√£o R√°pida** | LoRA Adapters | - | ‚è≥ A implementar |
| **Plasticidade Real** | - | Backpropamine (Cerebelo) | ‚è≥ A implementar |
| **Aten√ß√£o Neuromodulada** | Attention (Transformers) | Backpropamine (Modula√ß√£o) | ‚è≥ A implementar |
| **Consolida√ß√£o** | Fine-tuning Incremental | Consolida√ß√£o Durante Sono | ‚è≥ A implementar |
| **Sistema RL** | PPO | TD Learning (Melhorar) | ‚úÖ Estrutura |
| **Feedback** | Impl√≠cito + Emocional | - | ‚úÖ Implementado |

**Legenda**:
- ‚úÖ = Implementado
- ‚è≥ = A implementar
- `-` = N√£o aplic√°vel

---

## üéØ Onde Aplicar Tecnologias Experimentais

### 1. Backpropamine

#### ‚úÖ **Aplicar em**:

**a) Cerebelo (Modelo Pequeno 100M-500M)**
- **Por qu√™**: Modelo pequeno = menor overhead
- **Fun√ß√£o**: Aprender padr√µes espec√≠ficos e automatizar
- **Risco**: Baixo (modelo pequeno)
- **Benef√≠cio**: Alto (especializa√ß√£o real)

```mermaid
graph LR
    A[Padr√µes Frequentes] --> B[Cerebelo<br/>100M-500M]
    B --> C[Backpropamine]
    C --> D[Automatiza√ß√£o]
    
    style B fill:#ffcccc
    style C fill:#ffcccc
```

**b) Aten√ß√£o Neuromodulada**
- **Por qu√™**: Controle contextual de aten√ß√£o
- **Fun√ß√£o**: Modular onde focar baseado em contexto
- **Risco**: M√©dio (integra√ß√£o com Transformers)
- **Benef√≠cio**: Alto (aten√ß√£o biol√≥gica real)

```mermaid
graph LR
    A[Contexto] --> B[Neuromodula√ß√£o]
    B --> C[Backpropamine]
    C --> D[Attention Weights]
    D --> E[Foco Contextual]
    
    style C fill:#ffcccc
```

**c) Consolida√ß√£o Hipocampo ‚Üí C√≥rtex**
- **Por qu√™**: Transfer√™ncia real de conhecimento
- **Fun√ß√£o**: Consolidar mem√≥rias importantes no modelo base
- **Risco**: Alto (modificar modelo base)
- **Benef√≠cio**: Muito Alto (consolida√ß√£o biol√≥gica)

```mermaid
graph LR
    A[Hipocampo<br/>Mem√≥rias Importantes] --> B[Replay]
    B --> C[Backpropamine]
    C --> D[PFC<br/>Modelo Base]
    D --> E[Conhecimento Consolidado]
    
    style C fill:#ffcccc
```

#### ‚ùå **N√ÉO Aplicar em**:

**a) LLM Base Principal (7B+)**
- **Por qu√™**: Overhead muito alto, n√£o testado
- **Alternativa**: LoRA Adapters (pragm√°tico)

**b) Adapta√ß√£o R√°pida por Contexto**
- **Por qu√™**: LoRA √© mais eficiente
- **Alternativa**: LoRA Adapters (pragm√°tico)

---

### 2. Consolida√ß√£o Durante "Sono"

#### ‚úÖ **Aplicar em**:

**a) Transfer√™ncia Hipocampo ‚Üí C√≥rtex**
- **Por qu√™**: Processo biol√≥gico real
- **Fun√ß√£o**: Consolidar mem√≥rias epis√≥dicas importantes
- **Frequ√™ncia**: Di√°ria ou ap√≥s N experi√™ncias
- **Risco**: M√©dio (requer valida√ß√£o)

```mermaid
graph TB
    A[Agendamento<br/>Di√°rio/Peri√≥dico] --> B[Sele√ß√£o de<br/>Mem√≥rias Importantes]
    B --> C[Replay de<br/>Mem√≥rias]
    C --> D[Fine-tuning<br/>Incremental]
    D --> E[MAS<br/>Preserva√ß√£o]
    E --> F[Transfer√™ncia<br/>para PFC]
    F --> G[Limpeza<br/>Hipocampo]
    
    style A fill:#ffcccc
    style F fill:#ffcccc
```

**b) Replay de Mem√≥rias Significativas**
- **Por qu√™**: Reativa√ß√£o biol√≥gica real
- **Fun√ß√£o**: Reativar e consolidar experi√™ncias
- **Crit√©rio**: Mem√≥rias com alta import√¢ncia (MAS)
- **Risco**: Baixo (j√° temos replay b√°sico)

**c) Limpeza Seletiva do Hipocampo**
- **Por qu√™**: Evitar overflow de mem√≥ria
- **Fun√ß√£o**: Remover mem√≥rias antigas n√£o consolidadas
- **Crit√©rio**: Idade + Import√¢ncia + Consolida√ß√£o
- **Risco**: Baixo (apenas limpeza)

#### ‚ùå **N√ÉO Aplicar em**:

**a) Consolida√ß√£o Cont√≠nua**
- **Por qu√™**: Muito custoso computacionalmente
- **Alternativa**: Fine-tuning incremental peri√≥dico

---

## üîç Verifica√ß√£o: Temos Tudo Incorporado?

### ‚úÖ Componentes Implementados

1. ‚úÖ **LLM Base** (CodeLlama 3B)
2. ‚úÖ **RAG** (PostgreSQL + pgvector)
3. ‚úÖ **MAS** (Memory Aware Synapses)
4. ‚úÖ **RL Estrutura** (PPO)
5. ‚úÖ **Feedback** (Impl√≠cito + Emocional)

### ‚è≥ Componentes a Implementar (Pragm√°ticos)

1. ‚è≥ **LoRA Adapters** - Adapta√ß√£o r√°pida
2. ‚è≥ **Integra√ß√£o RL + LoRA** - Controle de adapters
3. ‚è≥ **Replay Melhorado** - Mem√≥rias importantes
4. ‚è≥ **Fine-tuning Incremental** - Consolida√ß√£o pragm√°tica
5. ‚è≥ **Hierarquia de Mem√≥ria** - Sensorial ‚Üí Trabalho ‚Üí Curto ‚Üí Longo

### ‚è≥ Componentes a Implementar (Experimentais)

1. ‚è≥ **Backpropamine no Cerebelo** - Modelo pequeno
2. ‚è≥ **Backpropamine na Aten√ß√£o** - Neuromodula√ß√£o
3. ‚è≥ **Backpropamine na Consolida√ß√£o** - Transfer√™ncia
4. ‚è≥ **Consolida√ß√£o Durante Sono** - Processo offline
5. ‚è≥ **Cerebelo** - Modelo pequeno especializado

### ‚úÖ Processos Psicol√≥gicos Planejados

1. ‚úÖ **Estrutura Planejada** - Arquitetura h√≠brida definida
2. ‚è≥ **Implementa√ß√£o** - A fazer gradualmente

---

## üìà Plano de Implementa√ß√£o em Fases

### Fase 1: Base Pragm√°tica (Sprint 1-2)

**Objetivo**: Sistema funcional com tecnologias comprovadas

```mermaid
gantt
    title Fase 1: Base Pragm√°tica
    dateFormat  YYYY-MM-DD
    section Implementa√ß√£o
    LoRA Adapters           :a1, 2025-02-01, 1w
    Integra√ß√£o RL + LoRA    :a2, after a1, 1w
    Replay Melhorado        :a3, after a2, 1w
    Fine-tuning Incremental :a4, after a3, 1w
    Hierarquia de Mem√≥ria   :a5, after a4, 1w
```

**Entregas**:
- ‚úÖ LoRA Adapters funcionando
- ‚úÖ RL controlando adapters
- ‚úÖ Replay de mem√≥rias importantes
- ‚úÖ Fine-tuning incremental
- ‚úÖ Sistema funcional completo

---

### Fase 2: Experimenta√ß√£o (Sprint 3-4)

**Objetivo**: Validar tecnologias experimentais em componentes espec√≠ficos

```mermaid
gantt
    title Fase 2: Experimenta√ß√£o
    dateFormat  YYYY-MM-DD
    section Valida√ß√£o
    Backpropamine Cerebelo      :b1, 2025-03-01, 2w
    Backpropamine Aten√ß√£o       :b2, after b1, 2w
    Consolida√ß√£o Durante Sono   :b3, after b2, 2w
    Cerebelo Modelo Pequeno      :b4, after b3, 2w
```

**Entregas**:
- ‚úÖ Backpropamine validado no Cerebelo
- ‚úÖ Aten√ß√£o neuromodulada funcionando
- ‚úÖ Consolida√ß√£o durante sono implementada
- ‚úÖ Cerebelo especializado

---

### Fase 3: Integra√ß√£o Completa (Sprint 5-6)

**Objetivo**: Integrar tudo e otimizar

```mermaid
gantt
    title Fase 3: Integra√ß√£o
    dateFormat  YYYY-MM-DD
    section Integra√ß√£o
    Integra√ß√£o Completa         :c1, 2025-04-01, 2w
    Otimiza√ß√£o Performance      :c2, after c1, 2w
    Testes e Valida√ß√£o          :c3, after c2, 1w
    Documenta√ß√£o Final          :c4, after c3, 1w
```

**Entregas**:
- ‚úÖ Sistema completamente integrado
- ‚úÖ Performance otimizada
- ‚úÖ Testes completos
- ‚úÖ Documenta√ß√£o final

---

## üé® Diagrama de Arquitetura Completo

```mermaid
graph TB
    subgraph "Camada 0: Entrada"
        USER[Usu√°rio]
        LINUX[Linux Sistema]
    end
    
    subgraph "Camada 1: Percep√ß√£o"
        SENS[Sistema Sensorial<br/>Filesystem, Processos, Network]
        PERC[Percep√ß√£o<br/>Pattern Recognition<br/>Structure Parser]
    end
    
    subgraph "Camada 2: Mem√≥ria"
        SENS_MEM[Mem√≥ria Sensorial<br/>Cache]
        WORK_MEM[Mem√≥ria de Trabalho<br/>Contexto]
        SHORT_MEM[Mem√≥ria Curto Prazo<br/>RAG - Hipocampo]
        LONG_MEM[Mem√≥ria Longo Prazo<br/>LLM Base - C√≥rtex]
    end
    
    subgraph "Camada 3: Processamento"
        PFC[PFC: LLM Base<br/>CodeLlama 3B]
        LORA[LoRA Adapters<br/>Adapta√ß√£o R√°pida]
        ATT[Aten√ß√£o<br/>Neuromodulada*]
    end
    
    subgraph "Camada 4: Aprendizado"
        MAS[MAS<br/>Preserva√ß√£o]
        BACKPROP[Backpropamine*<br/>Cerebelo + Aten√ß√£o]
        RL[RL PPO<br/>Sistema Dopamin√©rgico]
    end
    
    subgraph "Camada 5: Consolida√ß√£o"
        REPLAY[Replay<br/>Mem√≥rias Importantes]
        FT[Fine-tuning<br/>Incremental]
        SLEEP[Consolida√ß√£o<br/>Durante Sono*]
    end
    
    subgraph "Camada 6: Processos Psicol√≥gicos"
        THINK[Pensamento]
        EMOT[Emo√ß√£o]
        MOTIV[Motiva√ß√£o]
        META[Metacogni√ß√£o]
        PROB[Resolu√ß√£o de Problemas]
        DEC[Tomada de Decis√£o]
        PLAN[Planejamento]
    end
    
    subgraph "Camada 7: A√ß√£o"
        MOTOR[Sistema Motor<br/>Tool Calling]
        AUTO[Sistema Aut√¥nomo<br/>Services]
    end
    
    USER --> SENS
    LINUX --> SENS
    SENS --> PERC
    PERC --> SENS_MEM
    SENS_MEM --> WORK_MEM
    WORK_MEM --> SHORT_MEM
    SHORT_MEM --> LONG_MEM
    
    SHORT_MEM --> PFC
    PFC --> LORA
    LORA --> ATT
    ATT --> BACKPROP
    
    RL --> LORA
    RL --> BACKPROP
    BACKPROP --> MAS
    MAS --> PFC
    
    SHORT_MEM --> REPLAY
    REPLAY --> FT
    FT --> SLEEP
    SLEEP --> LONG_MEM
    
    PFC --> THINK
    THINK --> EMOT
    EMOT --> MOTIV
    MOTIV --> PLAN
    THINK --> PROB
    THINK --> DEC
    PLAN --> META
    
    THINK --> MOTOR
    MOTOR --> AUTO
    AUTO --> LINUX
    
    style BACKPROP fill:#ffcccc
    style ATT fill:#ffcccc
    style SLEEP fill:#ffcccc
```

**Legenda**:
- `*` = Componente experimental (Backpropamine, Consolida√ß√£o durante sono)

---

## üìã Checklist de Implementa√ß√£o

### ‚úÖ Fase 1: Base Pragm√°tica

- [ ] **LoRA Adapters**
  - [ ] Implementar LoRA para CodeLlama 3B
  - [ ] Sistema de sele√ß√£o de adapters
  - [ ] Integra√ß√£o com LLM base
  
- [ ] **Integra√ß√£o RL + LoRA**
  - [ ] RL controla sele√ß√£o de adapters
  - [ ] Feedback integrado (impl√≠cito + emocional)
  - [ ] Ajuste de pol√≠tica baseado em feedback
  
- [ ] **Replay Melhorado**
  - [ ] Sele√ß√£o de mem√≥rias importantes (MAS)
  - [ ] Replay durante treinamento
  - [ ] Balanceamento replay vs. novos dados
  
- [ ] **Fine-tuning Incremental**
  - [ ] Fine-tuning com preserva√ß√£o MAS
  - [ ] Consolida√ß√£o peri√≥dica
  - [ ] Transfer√™ncia para modelo base
  
- [ ] **Hierarquia de Mem√≥ria**
  - [ ] Mem√≥ria sensorial (cache)
  - [ ] Mem√≥ria de trabalho (contexto)
  - [ ] Integra√ß√£o com RAG (curto prazo)
  - [ ] Integra√ß√£o com modelo base (longo prazo)

### ‚è≥ Fase 2: Experimenta√ß√£o

- [ ] **Backpropamine no Cerebelo**
  - [ ] Modelo pequeno (100M-500M)
  - [ ] Implementar Backpropamine
  - [ ] Validar em padr√µes espec√≠ficos
  
- [ ] **Backpropamine na Aten√ß√£o**
  - [ ] Neuromodula√ß√£o contextual
  - [ ] Integra√ß√£o com Transformers
  - [ ] Controle de aten√ß√£o
  
- [ ] **Consolida√ß√£o Durante Sono**
  - [ ] Agendamento de consolida√ß√£o
  - [ ] Sele√ß√£o de mem√≥rias importantes
  - [ ] Replay e consolida√ß√£o
  - [ ] Transfer√™ncia para modelo base
  
- [ ] **Cerebelo Especializado**
  - [ ] Modelo pequeno
  - [ ] Aprendizado de padr√µes
  - [ ] Automatiza√ß√£o

### ‚è≥ Fase 3: Integra√ß√£o

- [ ] **Integra√ß√£o Completa**
  - [ ] Todos os componentes integrados
  - [ ] Fluxo completo funcionando
  - [ ] Testes end-to-end
  
- [ ] **Otimiza√ß√£o**
  - [ ] Performance otimizada
  - [ ] Uso de mem√≥ria otimizado
  - [ ] Lat√™ncia reduzida
  
- [ ] **Documenta√ß√£o**
  - [ ] Documenta√ß√£o completa
  - [ ] Exemplos de uso
  - [ ] Guias de implementa√ß√£o

---

## üéØ Resumo Final

### O Que Temos

‚úÖ **Base S√≥lida**:
- LLM Base (CodeLlama 3B)
- RAG (PostgreSQL + pgvector)
- MAS (Preserva√ß√£o)
- RL Estrutura (PPO)
- Feedback (Impl√≠cito + Emocional)

### O Que Vamos Adicionar (Pragm√°tico)

‚è≥ **Fase 1**:
- LoRA Adapters
- Integra√ß√£o RL + LoRA
- Replay Melhorado
- Fine-tuning Incremental
- Hierarquia de Mem√≥ria

### O Que Vamos Experimentar (Experimental)

‚è≥ **Fase 2**:
- Backpropamine no Cerebelo
- Backpropamine na Aten√ß√£o
- Consolida√ß√£o Durante Sono
- Cerebelo Especializado

### Abordagem Final

**H√≠brida**: 
- **Pragm√°tico** onde necess√°rio (sistema funcional)
- **Experimental** onde adiciona valor real (componentes espec√≠ficos)
- **Evolutivo** (pode melhorar com pesquisa)

---

## üìö Refer√™ncias

### Papers Fundamentais

1. **Backpropamine**: Miconi et al. (2020) - [2002.10585](https://arxiv.org/abs/2002.10585)
2. **Differentiable Plasticity**: Miconi et al. (2018) - [1804.02464](https://arxiv.org/abs/1804.02464)
3. **MAS**: Aljundi et al. (2017) - [1711.09601](https://arxiv.org/abs/1711.09601)
4. **RAG**: Lewis et al. (2020) - [2005.11401](https://arxiv.org/abs/2005.11401)
5. **LoRA**: Hu et al. (2021) - [2106.09685](https://arxiv.org/abs/2106.09685)

### Documenta√ß√£o do Projeto

- `docs/neuroplasticity-infrastructure/REVISAO-ARQUITETURA-2025.md`
- `docs/neuroplasticity-infrastructure/NP-001-synaptic-plasticity.md`
- `ARQUITETURA_BIOLOGICA.md`
- `PLANO_REDESENHO.md`

---

**Data**: 2025-01-27  
**Vers√£o**: 2.0  
**Status**: üü° Proposta Final - Aguardando Aprova√ß√£o

