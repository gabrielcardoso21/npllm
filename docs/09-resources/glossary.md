# Glossário de Termos Técnicos

## A

**Adaptive Learning Rate**: Taxa de aprendizado que se adapta durante treinamento (ex: Adam, RMSprop)

**Attention Mechanism**: Mecanismo que permite modelo focar em partes relevantes do input

## B

**Backpropamine**: Técnica de plasticidade neuromodulada diferenciável

**Backward Transfer (BWT)**: Métrica que mede impacto de aprender novas tarefas em tarefas antigas

**Catastrophic Forgetting**: Fenômeno onde modelo esquece conhecimento anterior ao aprender novo

## C

**Continual Learning**: Aprendizado sequencial de múltiplas tarefas sem esquecer anteriores

**Consolidation**: Processo de transferir memória de curto para longo prazo

## D

**Differentiable Plasticity**: Plasticidade sináptica que pode ser treinada via backpropagation

**Domain Adaptation**: Adaptação de modelo de um domínio para outro

**Dynamic Networks**: Redes que modificam estrutura durante execução

## E

**Elastic Weight Consolidation (EWC)**: Técnica que preserva parâmetros importantes durante novo aprendizado

**Embedding**: Representação vetorial de texto ou outros dados

**Episodic Memory**: Memória de eventos específicos

## F

**Few-Shot Learning**: Aprendizado com poucos exemplos

**Fine-tuning**: Ajuste fino de modelo pré-treinado em dados específicos

**Forward Transfer (FWT)**: Métrica que mede quanto conhecimento anterior ajuda em novas tarefas

## H

**Hebbian Learning**: Regra de aprendizado: "neurônios que disparam juntos, conectam-se juntos"

## I

**In-Context Learning**: Capacidade de LLMs aprenderem do contexto sem atualizar parâmetros

## K

**Knowledge Distillation**: Transferência de conhecimento de modelo grande para pequeno

## L

**Long-Term Potentiation (LTP)**: Fortalecimento de sinapses após estimulação repetida

**Long-Term Depression (LTD)**: Enfraquecimento de sinapses quando não utilizadas

## M

**Memory Aware Synapses (MAS)**: Técnica que identifica automaticamente parâmetros importantes

**Meta-Learning**: Aprendizado de como aprender (learn to learn)

**Mixture of Experts (MoE)**: Arquitetura com múltiplos especialistas e roteamento adaptativo

## N

**Neural Architecture Search (NAS)**: Busca automática de arquiteturas de redes neurais

**Neuromodulation**: Processo pelo qual neurotransmissores modulam atividade e plasticidade

**Neuroplasticity**: Capacidade do cérebro de se reorganizar e formar novas conexões

## O

**Online Learning**: Aprendizado de fluxo contínuo de dados, processando incrementalmente

## P

**Plasticity**: Capacidade de adaptação e mudança

**Progressive Neural Networks**: Arquitetura que cresce incrementalmente preservando conhecimento

**Prompt Engineering**: Técnica de design de prompts para melhorar performance de LLMs

## R

**RAG (Retrieval Augmented Generation)**: Técnica que combina retrieval com geração de texto

**Replay**: Reapresentar dados de tarefas anteriores durante novo aprendizado

## S

**Semantic Memory**: Memória de conhecimento factual

**Spike-Timing Dependent Plasticity (STDP)**: Plasticidade baseada no timing relativo de spikes

**Spiking Neural Networks (SNNs)**: Redes que processam informações através de spikes discretos

## T

**Tool Calling**: Capacidade de LLMs chamarem funções externas

**Transfer Learning**: Aplicar conhecimento aprendido em uma tarefa para outra

## V

**Vector Database**: Database especializada em armazenar e buscar embeddings

## W

**Working Memory**: Memória temporária de curto prazo

## Referências Cruzadas

- Para definições detalhadas, consulte os documentos específicos
- Use Ctrl+F para buscar termos neste documento
- Termos relacionados estão agrupados por conceito

